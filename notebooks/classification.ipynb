{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "data = pd.read_csv('../data/raw/clinical_dataset.csv', sep=';').drop(columns=['weight_loss',\n",
    "                                           'exhaustion_score',\n",
    "                                           'gait_speed_slower',\n",
    "                                           'grip_strength_abnormal',\n",
    "                                           'low_physical_activity'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "filled_data = data\n",
    "for columns in data: \n",
    "    if (data[columns].dtype == object):\n",
    "        data[columns].replace('Test not adequate', np.nan, inplace=True)\n",
    "        data[columns].replace('test non realizable', np.nan, inplace=True)\n",
    "    elif (data[columns].dtype == np.float64 or data[columns].dtype == np.int64):\n",
    "        data[columns].replace(999, np.nan, inplace=True)\n",
    "\n",
    "\n",
    "# Remove null values\n",
    "# TODO: Remove entries of features with missing values\n",
    "# TODO: Remove features with many missing values \n",
    "# Find rows where there are mon than 1 null value\n",
    "\n",
    "\n",
    "for column in data:\n",
    "    # Rplace nan values with the median of each column\n",
    "    if data[column].dtype != object and data[column].dtype != bool:\n",
    "        data[column].fillna(data[column].median(), inplace=True)\n",
    "\n",
    "    # Replace categorical values with the most used column value \n",
    "    elif (data[column].dtype != np.float64 and data[column].dtype != np.int64):\n",
    "         data[column].fillna(data[column].value_counts().index[0], inplace=True)\n",
    "\n",
    "# Order categorical data\n",
    "ordered_categories = {\n",
    "    'fried': ['Non frail', 'Pre-frail', 'Frail'],\n",
    "    'gender': ['F', 'M'],\n",
    "    'gait_optional_binary': [True, False],\n",
    "    'ortho_hypotension': ['No', 'Yes'],\n",
    "    'vision': ['Sees well', 'Sees moderately','Sees poorly'  ],\n",
    "    'audition': ['Hears well', 'Hears moderately', 'Hears poorly' ],\n",
    "    'weight_loss': ['No', 'Yes'],\n",
    "    'balance_single': ['>5 sec', '<5 sec'],\n",
    "    'gait_speed_slower': ['No', 'Yes'],\n",
    "    'grip_strength_abnormal': ['No', 'Yes'],\n",
    "    'low_physical_activity': ['No', 'Yes'],\n",
    "    'memory_complain': ['No', 'Yes'],\n",
    "    'sleep': ['No sleep problem', 'Occasional sleep problem', 'Permanent sleep problem'],\n",
    "    'living_alone': ['No', 'Yes'],\n",
    "    'leisure_club': ['Yes', 'No'],\n",
    "    'house_suitable_participant': ['Yes', 'No'],\n",
    "    'house_suitable_professional': ['Yes', 'No'],\n",
    "    'health_rate': [  '5 - Excellent', '4 - Good', '3 - Medium', '2 - Bad', '1 - Very bad'],\n",
    "    'health_rate_comparison': [ '5 - A lot better', '4 - A little better', '3 - About the same', '2 - A little worse',\n",
    "  '1 - A lot worse'],\n",
    "    'activity_regular': ['> 5 h per week', '> 2 h and < 5 h per week', '< 2 h per week',  'No'],\n",
    "    'smoking': ['Never smoked', 'Past smoker (stopped at least 6 months)', 'Current smoker']    \n",
    "}\n",
    "# encode data\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "for column in data:\n",
    "    if data[column].dtype == np.object or data[column].dtype == np.bool:\n",
    "        encoder.fit(data[column])\n",
    "        encoder.classes_ = ordered_categories[column]\n",
    "        data[column] = encoder.transform(data[column]) \n",
    "        \n",
    "data.to_csv('../data/preprocessed/clinical_dataset_notebook.csv', sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset to train and test \n",
    "data_shape = data.shape[0]\n",
    "splitter = int(np.ceil(0.8*data_shape))\n",
    "train_data = data.iloc[:splitter]\n",
    "test_data = data.iloc[splitter:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tree best parameters : {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 25, 'min_weight_fraction_leaf': 0.0}\nTree best estimator : DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n                       max_depth=5, max_features=None, max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=20, min_samples_split=25,\n                       min_weight_fraction_leaf=0.0, presort='deprecated',\n                       random_state=None, splitter='best')\nTree best score : 0.5737236033146218\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#finding best fit with gridsearch\n",
    "param_grid = {'min_samples_leaf':np.arange(20,50,5),\n",
    "              'min_samples_split':np.arange(20,50,5),\n",
    "              'max_depth':np.arange(3,6),\n",
    "              'min_weight_fraction_leaf':np.arange(0,0.4,0.1),\n",
    "              'criterion':['gini','entropy']}\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "tree_search = GridSearchCV(clf, param_grid)\n",
    "\n",
    "X = train_data.drop(['fried','part_id'] ,axis=1)\n",
    "Y = train_data['fried']\n",
    "\n",
    "tree_search.fit(X,Y)\n",
    "\n",
    "print(\"Tree best parameters :\",tree_search.best_params_)\n",
    "print(\"Tree best estimator :\",tree_search.best_estimator_ )\n",
    "print(\"Tree best score :\",tree_search.best_score_ )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='random')"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# Model Decision trees\n",
    "tree_classifier = tree.DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
    "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=20, min_samples_split=25,\n",
    "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "                       random_state=None, splitter='best')\n",
    "X = train_data.drop(['fried','part_id'] ,axis=1)\n",
    "tree_classifier.fit(X, train_data['fried'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.17592592592592593\n[[0.39814815 0.18518519 0.03703704]\n [0.14814815 0.12962963 0.05555556]\n [0.00925926 0.03703704 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "test_without_id = test_data.drop(['fried','part_id'], axis=1)\n",
    "y_predict = tree_classifier.predict(test_without_id)\n",
    "\n",
    "# Evaluate results\n",
    "results = {'id': test_data['part_id'],\n",
    "                        'Actual': test_data['fried'],\n",
    "                        'predicted': y_predict}\n",
    "\n",
    "\n",
    "conf_m = confusion_matrix(results['Actual'],results['predicted'], normalize='all')\n",
    "print(np.mean(np.diag(conf_m)))\n",
    "results = pd.DataFrame({'accurancy': [conf_m]})\n",
    "\n",
    "print(results['accurancy'][0])\n",
    "# Save results\n",
    "results.to_csv('../data/results/decision_trees_classification_notebook.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}